{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5803ab37302008fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''\n",
    "Important modules:\n",
    "- Dataset\n",
    "- Gaussian Diffusion\n",
    "- Tokenizer\n",
    "- Trainer\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "492f8ecc2b8ff0f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def cosine_beta_schedule(timesteps, s = 0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule\n",
    "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps, dtype = torch.float64)\n",
    "    \n",
    "    # Directly from the paper although more testing is required.\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0, 0.9999)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25100418c27632e0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (72868075.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[1], line 26\u001B[0;36m\u001B[0m\n\u001B[0;31m    \u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Load required paremeters\n",
    "\n",
    "        betas = cosine_beta_schedule(timesteps=1000)\n",
    "        alphas = 1-betas\n",
    "        alphas_cumprod = torch.cumprod(alphas)\n",
    "        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1,0), value=1) # add padding to the front and none at the end (at every index, the prev. value is available at that index)\n",
    "        \n",
    "        # Calculate the remaining values needed here to easily calculate the posterior varianes downstream\n",
    "        \n",
    "        posterior_variance = betas * (1-alphas_cumprod_prev) / (1-alphas_cumprod)\n",
    "        \n",
    "        # Calculate remaining important values including text vals\n",
    "        \n",
    "        \n",
    "    def denoise_fn():\n",
    "        # TODO\n",
    "        return pred_noise\n",
    "        \n",
    "    def extract(a, t, x_shape):\n",
    "        b, *_ = t.shape\n",
    "        out = a.gather(-1, t) # t gives us the time steps that we'd like to get values for (from a)\n",
    "        return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "        \n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        mean = extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "        variance = extract(1. - self.alphas_cumprod, t, x_start.shape)\n",
    "        log_variance = extract(self.log_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    # Just applying the formulas presented in the paper\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
    "            extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n",
    "    \n",
    "    def q_sample(self, x_start, t, noise = None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        return (\n",
    "            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
    "            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n",
    "        )        \n",
    "    \n",
    "    \n",
    "    @torch.inference_mode()\n",
    "    def p_sample_loop(self, shape, cond = None, cond_scale = 1.):\n",
    "        device = self.betas.device\n",
    "\n",
    "        b = shape[0]\n",
    "        img = torch.randn(shape, device=device)\n",
    "\n",
    "        for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "            img = self.p_sample(img, torch.full((b,), i, device=device, dtype=torch.long), cond = cond, cond_scale = cond_scale)\n",
    "\n",
    "        return unnormalize_img(img)\n",
    "    \n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def p_sample(self, x, t, cond = None, cond_scale = 1., clip_denoised = True):\n",
    "        b, *_, device = *x.shape, x.device\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(x = x, t = t, clip_denoised = clip_denoised, cond = cond, cond_scale = cond_scale)\n",
    "        noise = torch.randn_like(x)\n",
    "        # no noise when t == 0\n",
    "        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n",
    "        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n",
    "\n",
    "    \n",
    "    # Reverse -> recon\n",
    "    def p_losses(self, x_start, t, cond = None, noise = None, **kwargs):\n",
    "        b, c, f, h, w, device = *x_start.shape, x_start.device\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n",
    "\n",
    "        if is_list_str(cond):\n",
    "            cond = bert_embed(tokenize(cond), return_cls_repr = self.text_use_bert_cls)\n",
    "            cond = cond.to(device)\n",
    "\n",
    "        x_recon = self.denoise_fn(x_noisy, t, cond = cond, **kwargs)\n",
    "\n",
    "        if self.loss_type == 'l1':\n",
    "            loss = F.l1_loss(noise, x_recon)\n",
    "        elif self.loss_type == 'l2':\n",
    "            loss = F.mse_loss(noise, x_recon)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        return loss\n",
    "        \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:27:27.112365Z",
     "start_time": "2024-03-03T23:27:27.076211Z"
    }
   },
   "id": "d1d16371285a7d86",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''\n",
    "Training (General structure)\n",
    "'''\n",
    "# load config parameters here\n",
    "step = 0\n",
    "max_steps = config[\"steps\"]\n",
    "opt = ...\n",
    "scaler = ...\n",
    "model = ...\n",
    "ema = ...\n",
    "\n",
    "# initialize training loop\n",
    "def train():\n",
    "    while step < max_steps:\n",
    "        # read from a dataloader\n",
    "\n",
    "        # Use torch lightning to scale and train\n",
    "        with autocast(enabled=amp):\n",
    "            data = next(data_loader).cuda()\n",
    "            loss = model(\n",
    "                data,\n",
    "            )\n",
    "            scaler.scale(loss/gradient_accumulate_scaler).backward()\n",
    "            \n",
    "        # Save content at regular intervals\n",
    "        \n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        step +=1\n",
    "        \n",
    "    print(\"Training completed!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "842421419649db5c",
   "execution_count": 0
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
